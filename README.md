# Neural Network from Scratch without using any frameworks.
## Overview
Welcome to my project where I built a neural network from the ground up using only mathematical principles and Python. This project demonstrates the fundamentals of neural networks without relying on popular deep learning libraries like TensorFlow or PyTorch.

## Project Highlights
- Data Preparation: Loaded and preprocessed the MNIST dataset to normalize pixel values and split into training and development sets.
- Initialization: Created random weight matrices and bias vectors.
- Activation Functions: Implemented ReLU and Softmax from scratch.
- Forward Propagation: Computed activations through the network layers.
- Backward Propagation: Calculated gradients for weight and bias updates.
- Parameter Updates: Applied gradient descent to optimize the network.
- Evaluation: Achieved impressive accuracy on the training set!
  
## Why This Matters
  Understanding the math behind neural networks is crucial for building a strong foundation in deep learning. It enhances the appreciation for the complexities involved and equips one with the skills to innovate and solve problems from first principles. Mastering the underlying mathematics enables the development of more efficient and customized models, effective troubleshooting, and contributes to advancing the field of AI.

## Results
- Iteratively trained the network and evaluated its performance.
- Achieved significant improvement in accuracy over 500 iterations.
  
### Getting Started
**Prerequisites**
- Python 3.x
- NumPy
- Pandas
- Matplotlib

### Usage
1. Load and preprocess the MNIST dataset.
2. Initialize the parameters (weights and biases).
3. Implement and run the forward propagation, backward propagation, and gradient descent functions.
4. Evaluate the network's performance and adjust hyperparameters as necessary.
   
### Contributing
Contributions are welcome! Please feel free to submit a Pull Request or open an Issue for any improvements or suggestions.

### Acknowledgements
Special thanks to the creators of the MNIST dataset and the developers of the libraries used in this project.

### Contact
Feel free to reach out with any questions or comments. I'm eager to hear your thoughts and any suggestions for further improvements!

